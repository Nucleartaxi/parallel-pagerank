---
title: "Cpts 411 Programming Project 5"
author: 
     - "Clancy Andrews"
     - "Alex Shirk"
header-includes:
   - \usepackage{amssymb}
   - \usepackage{amsmath}
   - \usepackage{graphicx,float}
   - \usepackage{natbib}
   - \usepackage{geometry}
   - \usepackage{xcolor}
   - \usepackage{courier}
output:
  pdf_document: default
fontsize: 11pt
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\break

# Introduction

|       For this project, our goal was to use a multithreaded implementation of the PageRank algorithm to estimate the ranks of nodes on a graph input. The PageRank of a node $u$ in a graph is used when determining the importance of a node throughout the network. In this particular instance, we can think of the nodes as webpages, and the edges between the nodes as hyperlinks to other webpages. It is worth noting that the graph is directed, since an edge can go from node $u$ to node $v$, but node $v$ need not necessarily have an edge (hyperlink) to node $u$ as well. We can consider the total degree of a node as the sum between the out degree and in degree of each node. The out degree is the number of outgoing edges from the particular node and the in degree is the number of edges coming in. 

|        The PageRank algorithm estimator is as follows. First, we start from every node in the graph. We then do a random walk of length $K$, keeping track of the number of times a particular node $u$ is visited. The estimated PageRank value for node $u$ is the number of time $u$ was visited divided by the total number of visits in the network. When progressing through a random walk, we can expect that the next visit to a node will either be one of the neighbors of the current node, or a completely random node in the graph. To account for this, the use of a dampening ratio $D$ will be used. It is worth noting that $D \in [0,1]$. If we toss a coin with $D$ probability of landing on heads and $1-D$ probability of landing on tails, we can say that if the coin lands on heads, we randomly select a node in the network to continue the walk on. If the coin lands tails, then we randomly select a neighboring node to continue the walk on.

|       With this logic, our goal was to observe how the algorithm will perform given different dampening ratios, different walk lengths, and different number of threads being used. Since the graphs that are being tested on are sparse, we used an adjacency list to hold the data provided. This allows the program to run faster than the alternative adjacency matrix.

\bigbreak

# Analysis

|       The data was collected on a personal computer, which utilizes an Intel i9-10900K CPU at 3.70GHz, containing 10 cores and 20 logical processors. The computer is running on Windows 11 Pro 23H2 Build 22631.2715 and has 32 GB Memory (RAM). When running the program, we got the following top five Google webpages based on the PageRank algorithm with the number of steps in the random walk $K = 100$, the number of processes used $p = 16$, and the dampening ratio $D = 0.25$.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

# Set options to display numbers without scientific notation
options(scipen = 999)

df = data.frame(
  Node = c(597621, 163075, 537039, 41909, 504140),
  PageRank = c(0.000078, 0.000077, 0.000077, 0.000070, 0.000064)
)

kable(df, format = "markdown", 
      caption = "Node and corresponding PageRank estimate for the node given K is 100, p is 16, and D is 0.25.")
```
Our first test we to see the effect of the estimate when we change the dampening ratio. The next two tables show similar results to table (1), but with dampening ratios of 0.5 and 0.75, respectively.

```{r echo=FALSE, message=FALSE, warning=FALSE}
df1 = data.frame(
  Node = c(163075, 537039, 597621, 605856, 551829),
  PageRank = c(0.000043, 0.000039, 0.000039, 0.000034, 0.000034)
)

kable(df1, format = "markdown", 
      caption = "Node and corresponding PageRank estimate for the node given K is 100, p is 16, and D is 0.50.")

df2 = data.frame(
  Node = c(163075, 537039, 597621, 605856, 819223),
  PageRank = c(0.000020, 0.000017, 0.000017, 0.000015, 0.000014)
)

kable(df2, format = "markdown", 
      caption = "Node and corresponding PageRank estimate for the node given K is 100, p is 16, and D is 0.75.")
```
Just visually, we can see that as the dampening ratio increases, the PageRank estimate decreases in value. However, the rank of each node (webpage) does not have much change. This is due to the fact that the dampening ratio only effects the likelihood to choose a new random node to start on. Since the nodes with higher estimates have a high total degree in the graph, they still will have a larger probability to be selected again later in the walk. This is also the case when we increase the number of steps in the random walk. Going off of how the estimate is calculated, the fraction value decreases since the number of vertices multiplied by the number of steps $K$ is in the denominator, resulting in its increase. The next test we did was on the time between the algorithm when using 1 thread up to 16 threads.




```{r echo=FALSE, message=FALSE, warning=FALSE}
#Libraries
library(ggplot2)
library(stats)

#Import data for analysis
damp = read.csv2("dampening.csv", header = FALSE, sep = ",")
colnames(damp) = c("Time", "K", "p", "D")

length = read.csv2("length.csv", header=FALSE, sep = ",")
colnames(length) = c("Time", "K", "p", "D")

#Extract Serial Time from Data
serial_time_damp = subset(damp, p == 1)$Time
serial_time_length = subset(length, p == 1)$Time

#Get the parallel times for each P value
parallel_time_damp = data.frame(matrix(ncol = length(unique(damp$p)), 
                                       nrow = dim(damp)[1]))
colnames(parallel_time_damp) = c("1", "2", "4", "8", "16")

parallel_time_length = data.frame(matrix(ncol = length(unique(length$p)), 
                                         nrow = dim(length)[1]))
colnames(parallel_time_length) = c("1", "2", "4", "8", "16")

for (i in colnames(parallel_time_damp)) {
  p_value = as.numeric(i)
  data = damp$Time[damp$p == p_value]
  parallel_time_damp[, i] = data
}

for (i in colnames(parallel_time_length)) {
  p_value = as.numeric(i)
  data = length$Time[length$p == p_value]
  parallel_time_length[, i] = data
}

#Calculate the speed up
speedup_damp= data.frame(matrix(ncol = length(unique(damp$p)), nrow = 3))
colnames(speedup_damp) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_damp)) {
  speedup_damp[,i] = (as.numeric(serial_time_damp)/
                        as.numeric(parallel_time_damp[,i]))[1:3]
}

row.names(speedup_damp) = unique(damp$D)

speedup_length= data.frame(matrix(ncol = length(unique(length$p)), nrow = 5))
colnames(speedup_length) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_length)) {
  speedup_length[,i] = (as.numeric(serial_time_length)/
                          as.numeric(parallel_time_length[,i]))[1:5]
}

row.names(speedup_length) = unique(length$K)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
kable(speedup_damp, row.names = TRUE, 
      caption = "Speed up for corresponding $D$ (rows) dampening ratios and $p$ (columns) number of processes.")
```
The 


```{r echo=FALSE, message=FALSE, warning=FALSE}
kable(speedup_length, row.names = TRUE, 
      caption = "Speed up for corresponding $K$ (rows) number of steps in the random walk and $p$ (columns) number of processes.")
```


\break
# Analysis Code

The following is the code used for analyzing the collected data from the program:

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
#Libraries
library(ggplot2)
library(knitr)
library(stats)

# Set options to display numbers without scientific notation
options(scipen = 999)

df = data.frame(
  Node = c(597621, 163075, 537039, 41909, 504140),
  PageRank = c(0.000078, 0.000077, 0.000077, 0.000070, 0.000064)
)

kable(df, format = "markdown", 
      caption = "Node and corresponding PageRank estimate for the node given K is 100, p is 16, and D is 0.25.")

df1 = data.frame(
  Node = c(163075, 537039, 597621, 605856, 551829),
  PageRank = c(0.000043, 0.000039, 0.000039, 0.000034, 0.000034)
)

kable(df1, format = "markdown", 
      caption = "Node and corresponding PageRank estimate for the node given K is 100, p is 16, and D is 0.50.")

df2 = data.frame(
  Node = c(163075, 537039, 597621, 605856, 819223),
  PageRank = c(0.000020, 0.000017, 0.000017, 0.000015, 0.000014)
)

kable(df2, format = "markdown", 
      caption = "Node and corresponding PageRank estimate for the node given K is 100, p is 16, and D is 0.75.")

#Import data for analysis
damp = read.csv2("dampening.csv", header = FALSE, sep = ",")
colnames(damp) = c("Time", "K", "p", "D")

length = read.csv2("length.csv", header=FALSE, sep = ",")
colnames(length) = c("Time", "K", "p", "D")

#Extract Serial Time from Data
serial_time_damp = subset(damp, p == 1)$Time
serial_time_length = subset(length, p == 1)$Time

#Get the parallel times for each P value
parallel_time_damp = data.frame(matrix(ncol = length(unique(damp$p)), 
                                       nrow = dim(damp)[1]))
colnames(parallel_time_damp) = c("1", "2", "4", "8", "16")

parallel_time_length = data.frame(matrix(ncol = length(unique(length$p)), 
                                         nrow = dim(length)[1]))
colnames(parallel_time_length) = c("1", "2", "4", "8", "16")

for (i in colnames(parallel_time_damp)) {
  p_value = as.numeric(i)
  data = damp$Time[damp$p == p_value]
  parallel_time_damp[, i] = data
}

for (i in colnames(parallel_time_length)) {
  p_value = as.numeric(i)
  data = length$Time[length$p == p_value]
  parallel_time_length[, i] = data
}

#Calculate the speed up
speedup_damp= data.frame(matrix(ncol = length(unique(damp$p)), nrow = 3))
colnames(speedup_damp) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_damp)) {
  speedup_damp[,i] = (as.numeric(serial_time_damp)/
                        as.numeric(parallel_time_damp[,i]))[1:3]
}

row.names(speedup_damp) = unique(damp$D)

speedup_length= data.frame(matrix(ncol = length(unique(length$p)), nrow = 5))
colnames(speedup_length) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_length)) {
  speedup_length[,i] = (as.numeric(serial_time_length)/
                          as.numeric(parallel_time_length[,i]))[1:5]
}

row.names(speedup_length) = unique(length$K)


#Tables for speedup and timings
kable(speedup_damp, row.names = TRUE, 
      caption = "Speed up for corresponding $D$ (rows) dampening ratios and $p$ (columns) number of processes.")

kable(speedup_length, row.names = TRUE, 
      caption = "Speed up for corresponding $K$ (rows) number of steps in the random walk and $p$ (columns) number of processes.")


```


\break
# Session Info
```{r}
sessionInfo()
```