---
title: "Cpts 411 Programming Project 5"
author: 
     - "Clancy Andrews"
     - "Alex Shirk"
header-includes:
   - \usepackage{amssymb}
   - \usepackage{amsmath}
   - \usepackage{graphicx,float}
   - \usepackage{natbib}
   - \usepackage{geometry}
   - \usepackage{xcolor}
   - \usepackage{courier}
output:
  pdf_document: default
fontsize: 11pt
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\break

# Introduction

|       For this project, our goal was to use a multithreaded implementation of the PageRank algorithm to estimate the ranks of nodes on a graph input. The PageRank of a node $u$ in a graph is used when determining the importance of a node throughout the network. In this particular instance, we can think of the nodes as webpages, and the edges between the nodes as hyperlinks to other webpages. It is worth noting that the graph is directed, since an edge can go from node $u$ to node $v$, but node $v$ need not necessarily have an edge (hyperlink) to node $u$ as well. We can consider the total degree of a node as the sum between the out degree and in degree of each node. The out degree is the number of outgoing edges from the particular node and the in degree is the number of edges coming in. 

|        The PageRank algorithm estimator is as follows. First, we start from every node in the graph. We then do a random walk of length $K$, keeping track of the number of times a particular node $u$ is visited. The estimated PageRank value for node $u$ is the number of time $u$ was visited divided by the total number of visits in the network. When progressing through a random walk, we can expect that the next visit to a node will either be one of the neighbors of the current node, or a completely random node in the graph. To account for this, the use of a dampening ratio $D$ will be used. It is worth noting that $D \in [0,1]$. If we toss a coin with $D$ probability of landing on heads and $1-D$ probability of landing on tails, we can say that if the coin lands on heads, we randomly select a node in the network to continue the walk on. If the coin lands tails, then we randomly select a neighboring node to continue the walk on.

|       With this logic, our goal was to observe how the algorithm will perform given different dampening ratios, different walk lengths, and different number of threads being used. Since the graphs that are being tested on are sparse, we used an adjacency list to hold the data provided. This allows the program to run faster than the alternative adjacency matrix.

\bigbreak

# Analysis

|    The data was collected on a personal computer, which utilizes an Intel i9-10900K CPU at 3.70GHz, containing 10 cores and 20 logical processors (threads).


```{r echo=FALSE, message=FALSE, warning=FALSE}
#Libraries
library(ggplot2)
library(knitr)
library(stats)

#Import data for analysis
damp = read.csv2("dampening.csv", header = FALSE, sep = ",")
colnames(damp) = c("Time", "K", "p", "D")

length = read.csv2("length.csv", header=FALSE, sep = ",")
colnames(length) = c("Time", "K", "p", "D")

#Extract Serial Time from Data
serial_time_damp = subset(damp, p == 1)$Time
serial_time_length = subset(length, p == 1)$Time

#Get the parallel times for each P value
parallel_time_damp = data.frame(matrix(ncol = length(unique(damp$p)), nrow = dim(damp)[1]))
colnames(parallel_time_damp) = c("1", "2", "4", "8", "16")

parallel_time_length = data.frame(matrix(ncol = length(unique(length$p)), nrow = dim(length)[1]))
colnames(parallel_time_length) = c("1", "2", "4", "8", "16")

for (i in colnames(parallel_time_damp)) {
  p_value = as.numeric(i)
  data = damp$Time[damp$p == p_value]
  parallel_time_damp[, i] = data
}

for (i in colnames(parallel_time_length)) {
  p_value = as.numeric(i)
  data = length$Time[length$p == p_value]
  parallel_time_length[, i] = data
}

#Calculate the speed up
speedup_damp= data.frame(matrix(ncol = length(unique(damp$p)), nrow = 3))
colnames(speedup_damp) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_damp)) {
  speedup_damp[,i] = (as.numeric(serial_time_damp)/as.numeric(parallel_time_damp[,i]))[1:3]
}

row.names(speedup_damp) = unique(damp$D)

speedup_length= data.frame(matrix(ncol = length(unique(length$p)), nrow = 5))
colnames(speedup_length) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_length)) {
  speedup_length[,i] = (as.numeric(serial_time_length)/as.numeric(parallel_time_length[,i]))[1:5]
}

row.names(speedup_length) = unique(length$K)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}

```

```{r echo=FALSE, message=FALSE, warning=FALSE}

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
kable(speedup_damp, row.names = TRUE, caption = "Speed up for corresponding $D$ (rows) dampening ratios and $p$ (columns) number of processes.")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
kable(speedup_length, row.names = TRUE, caption = "Speed up for corresponding $K$ (rows) number of steps in the random walk and $p$ (columns) number of processes.")
```


\break
# Analysis Code

The following is the code used for analyzing the collected data from the program:

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
#Libraries
library(ggplot2)
library(knitr)
library(stats)

#Import data for analysis
damp = read.csv2("dampening.csv", header = FALSE, sep = ",")
colnames(damp) = c("Time", "K", "p", "D")

length = read.csv2("length.csv", header=FALSE, sep = ",")
colnames(length) = c("Time", "K", "p", "D")

#Extract Serial Time from Data
serial_time_damp = subset(damp, p == 1)$Time
serial_time_length = subset(length, p == 1)$Time

#Get the parallel times for each P value
parallel_time_damp = data.frame(matrix(ncol = length(unique(damp$p)), nrow = dim(damp)[1]))
colnames(parallel_time_damp) = c("1", "2", "4", "8", "16")

parallel_time_length = data.frame(matrix(ncol = length(unique(length$p)), nrow = dim(length)[1]))
colnames(parallel_time_length) = c("1", "2", "4", "8", "16")

for (i in colnames(parallel_time_damp)) {
  p_value = as.numeric(i)
  data = damp$Time[damp$p == p_value]
  parallel_time_damp[, i] = data
}

for (i in colnames(parallel_time_length)) {
  p_value = as.numeric(i)
  data = length$Time[length$p == p_value]
  parallel_time_length[, i] = data
}

#Calculate the speed up
speedup_damp= data.frame(matrix(ncol = length(unique(damp$p)), nrow = 3))
colnames(speedup_damp) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_damp)) {
  speedup_damp[,i] = (as.numeric(serial_time_damp)/as.numeric(parallel_time_damp[,i]))[1:3]
}

row.names(speedup_damp) = unique(damp$D)

speedup_length= data.frame(matrix(ncol = length(unique(length$p)), nrow = 5))
colnames(speedup_length) = c("1", "2", "4", "8", "16")

for (i in colnames(speedup_length)) {
  speedup_length[,i] = (as.numeric(serial_time_length)/as.numeric(parallel_time_length[,i]))[1:5]
}

row.names(speedup_length) = unique(length$K)


#Tables for speedup and timings
kable(speedup_damp, row.names = TRUE, caption = "Speed up for corresponding $D$ (rows) dampening ratios and $p$ (columns) number of processes.")

kable(speedup_length, row.names = TRUE, caption = "Speed up for corresponding $K$ (rows) number of steps in the random walk and $p$ (columns) number of processes.")


```


\break
# Session Info
```{r}
sessionInfo()
```



D = 0.75,0.5,0.25
p = 16
k = 100

163075 0.000020
537039 0.000017
597621 0.000017
605856 0.000015
819223 0.000014


163075 0.000043
537039 0.000039
597621 0.000039
605856 0.000034
551829 0.000034


597621 0.000078
163075 0.000077
537039 0.000077
41909 0.000070
504140 0.000064




p = 16
k = 100
d = 0.25


597621 0.000078
163075 0.000077
537039 0.000077
41909 0.000070
504140 0.000064